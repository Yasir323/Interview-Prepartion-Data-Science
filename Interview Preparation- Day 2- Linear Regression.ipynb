{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Interview Preparation- Day 2- Linear Regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yasir323/Interview-Prepartion-Data-Science/blob/master/Interview%20Preparation-%20Day%202-%20Linear%20Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qATDDu3RZa2n"
      },
      "source": [
        "### How To Learn Machine Learning Algorithms For Interviews\n",
        "\n",
        "## Linear Regression\n",
        "\n",
        "Theoretical Understanding:\n",
        "\n",
        "1. Linear Regression\n",
        "https://www.youtube.com/watch?v=1-OGRohmH2s&list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&index=29\n",
        "2. Multiple Linear Regression\n",
        "https://www.youtube.com/watch?v=5rvnlZWzox8&list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&index=34\n",
        "3. MultiCollinearity In Linear Regression\n",
        "https://www.youtube.com/watch?v=NAPhUDjgG_s&list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&index=32\n",
        "4. R square and Adjusted R square\n",
        "https://www.youtube.com/watch?v=WuuyD3Yr-js&list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&index=35\n",
        "5. Bias and Variance Trade-off\n",
        "https://www.youtube.com/watch?v=BqzgUnrNhFM&list=PLZoTAELRMXVPBTrWtJkn3wWQxZkmTXGwe&index=33\n",
        "6. Ridge and Lasso Regression\n",
        "https://www.youtube.com/watch?v=9lRv01HDU0s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ_AQbx5Za8D"
      },
      "source": [
        "##### Interview Question on Multicollinearity\n",
        "\n",
        "1. https://www.youtube.com/watch?v=tcaruVHXZwE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqZ1xXTyZa8w"
      },
      "source": [
        "## 1. What Are the Basic Assumption?(favourite)\n",
        "There are four assumptions associated with a linear regression model:\n",
        "\n",
        "1. **Linearity**: The relationship between X and the mean of Y is linear.\n",
        "2. **Little or No Autocorrelation**: Autocorrelation occurs when the residuals are not independent of each other. In other words when the value of y(x+1) is independent of the value of y(x).\n",
        "3. **Homoscedasticity**: The variance of residual is the same for any value of X.\n",
        "4. **Little or No Multicollinearity**: This phenomenon exists when the independent variables are found to be moderately or highly correlated.\n",
        "5. **Normality**: For any fixed value of X, Y is normally distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EbA1HB1fsou"
      },
      "source": [
        "### Linearity\r\n",
        "There should be a linear and additive relationship between dependent (response) variable and independent (predictor) variable(s). A linear relationship suggests that a change in response Y due to one unit change in X¹ is constant, regardless of the value of X¹. An additive relationship suggests that the effect of X¹ on Y is independent of other variables.\r\n",
        "\r\n",
        "**What if this condition is violated?**\r\n",
        "\r\n",
        "If you fit a linear model to a non-linear, non-additive data set, the regression algorithm would fail to capture the trend mathematically, thus resulting in an inefficient model. Also, this will result in erroneous predictions on an unseen data set.\r\n",
        "\r\n",
        "**Tests to check for linearity.**\r\n",
        "\r\n",
        "1. Graphical Method.\r\n",
        "\r\n",
        "  *First*:- To show to graph using predicted and actual value.\r\n",
        "\r\n",
        "  *Second*:- To show to graph using predicted and residual value\r\n",
        "\r\n",
        "2. Statistical Test\r\n",
        "\r\n",
        "  **Rainbow test**:- This test is used for checking the linearity of regression applied. Here we define two hypothesis statement.\r\n",
        "\r\n",
        "  *Null Hypo* – Regression is Linear\r\n",
        "\r\n",
        "  *Alternate hypo* – Regression is non-Linear\r\n",
        "\r\n",
        "With the help of using statsmodels.api library we check the linearity of regression:\r\n",
        "\r\n",
        "`import statsmodels.api as sm`\r\n",
        "\r\n",
        "`sm.stats.diagnostic.linear_rainbow(res=lin_reg) `"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwgLcrVal6za"
      },
      "source": [
        "### Little or no Autocorrelation\r\n",
        "The presence of correlation in error terms drastically reduces model’s accuracy. This usually occurs in time series models where the next instant is dependent on previous instant. If the error terms are correlated, the estimated standard errors tend to underestimate the true standard error.\r\n",
        "\r\n",
        "If this happens, it causes confidence intervals and prediction intervals to be narrower. Narrower confidence interval means that a 95% confidence interval would have lesser probability than 0.95 that it would contain the actual value of coefficients. Let’s understand narrow prediction intervals with an example:\r\n",
        "\r\n",
        "For example, the least square coefficient of X¹ is 15.02 and its standard error is 2.08 (without autocorrelation). But in presence of autocorrelation, the standard error reduces to 1.20. As a result, the prediction interval narrows down to (13.82, 16.22) from (12.94, 17.10).\r\n",
        "\r\n",
        "Also, lower standard errors would cause the associated p-values to be lower than actual. This will make us incorrectly conclude a parameter to be statistically significant.\r\n",
        "\r\n",
        "**Test to check for autocorrelation**\r\n",
        "\r\n",
        "**Graphical method**:\r\n",
        "\r\n",
        "Plot the ACF plot of residual to check the autocorrelation in data.\r\n",
        "If the graph look like cyclic graph their means residuals contain positive autocorrelation, If the graph look like alternative graph their means residuals contain negative autocorrelation.\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)\r\n",
        "\r\n",
        "Graph shows the positive autocorrelation because it look like the cyclic graph \r\n",
        "\r\n",
        "**Durbin-Watson(DW) Test**:- \r\n",
        "\r\n",
        "Durbin-Watson(DW) Test is Generally used to check the Autocorrelation.\r\n",
        "Durbin Watson Test Can be defined as:-\r\n",
        "\r\n",
        "![image.png](data:image/png;base64,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)\r\n",
        "\r\n",
        "In Durbin-Watson test statistic is approximately equal to 2*(1-r) where r is the sample autocorrelation of the residuals in the model. Thus, for r == 0, indicating no serial correlation, the test statistic equals 2.\r\n",
        "\r\n",
        "Range of Durbin Watson Test from 0 to 4, where 0-2 shows positive Autocorrelation 2 means NO Autocorrelation and 2-4 means Negative Autocorrelation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_ZcjrDOl6os"
      },
      "source": [
        "### Multicolinearity\r\n",
        "This phenomenon exists when the independent variables are found to be moderately or highly correlated. In a model with correlated variables, it becomes a tough task to figure out the true relationship of a predictors with response variable. In other words, it becomes difficult to find out which variable is actually contributing to predict the response variable.\r\n",
        "\r\n",
        "Another point, with presence of correlated predictors, the standard errors tend to increase. And, with large standard errors, the confidence interval becomes wider leading to less precise estimates of slope parameters.\r\n",
        "\r\n",
        "Also, when predictors are correlated, the estimated regression coefficient of a correlated variable depends on which other predictors are available in the model. If this happens, you’ll end up with an incorrect conclusion that a variable strongly / weakly affects target variable. Since, even if you drop one correlated variable from the model, its estimated regression coefficients would change. That’s not good!\r\n",
        "\r\n",
        "**Test to check multicollinearity**\r\n",
        "\r\n",
        "**Correlation coefficients**:- An easy way to detect multicollinearity is to calculate correlation coefficients for all pairs of predictor variables. If the correlation coefficient, r, is exactly +1 or -1, this is called perfect multicollinearity. If r is close to or exactly -1 or +1, one of the variables should be removed from the model if at all possible.\r\n",
        "\r\n",
        "**Variance Inflation Factor( VIF )**:- Another method to check multicollinearity is that Variance Inflation Factor is the quotient of variance in a model of multiple-term by the variance of the model with one term. It tells about multicollinearity(ie ratio). \r\n",
        "\r\n",
        " **VIF = 1/T**\r\n",
        "\r\n",
        "Where T is the Tolerance it measures the influence of one independent variable to all other independent variables. The tolerance is calculated with an initial regression analysis. Ia defined as the T = 1 – R² for the first step regression analysis. If the Tolerance is less than (T< 0.1) there might be multicollinearity in the data and if the Tolerance is less than 0.01(T < 0.01) there certainly is.\r\n",
        "\r\n",
        "If the VIF is 1 means data is not correlated if it is Between 1 To 5 there is moderately Correlated or greater than 5 is highly correlated.\r\n",
        "\r\n",
        "**Why removing highly correlated features is important?**\r\n",
        "\r\n",
        "The independent variable contains a stronger correlation, the more difficult it is to change one feature without changing another feature. It becomes difficult for the model to estimate the relationship between each independant variable and the target variable independently because the features tend to change in unison.\r\n",
        "\r\n",
        "**How to remove multicollinearity in data?**\r\n",
        "\r\n",
        "Suppose we have two features that are highly correlated then drop one feature from it and take another otherwise combine the two features and form new features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yPKjf5Kl6ZN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-gIjhD9l5_K"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhXtfJ1vZa9A"
      },
      "source": [
        "##  2. Advantages\n",
        "1. Linear regression performs exceptionally well for linearly separable data\n",
        "2. Easy to implement and train the model\n",
        "3. It can handle overfitting using dimensionlity reduction techniques and cross validation and regularization \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHi_W9GZZa9X"
      },
      "source": [
        "## 3. Disadvantages\n",
        "1. Sometimes Lot of Feature Engineering Is required\n",
        "2. If the independent features are correlated it may affect performance\n",
        "3. It is often quite prone to noise and overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pozFwB6HZa9g"
      },
      "source": [
        "## 4. Whether Feature Scaling is required?\n",
        "Yes\n",
        "## 5. Impact of Missing Values?\n",
        "It is sensitive to missing values\n",
        "## 6. Impact of outliers?\n",
        "linear regression needs the relationship between the independent and dependent variables to be linear. It is also important to check for outliers since linear regression is sensitive to outlier effects.\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GU74zkHZa93"
      },
      "source": [
        "##### Types of Problems it can solve(Supervised)\n",
        "1. Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU1Qy6_6Za95"
      },
      "source": [
        "##### Overfitting And Underfitting\n",
        "HomeWork?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8O3SbDXZa-C"
      },
      "source": [
        "##### Different Problem statement you can solve using Linear Regression\n",
        "1. Advance House Price Prediction\n",
        "2. Flight Price Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpfxURCcZa-J"
      },
      "source": [
        "#### Practical Implementation\n",
        "1. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53WmUrvyZa-N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}